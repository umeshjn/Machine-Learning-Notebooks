{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Food is the basic neccessity of the of all living creatures. Humans are the only species who have created their own cuisines using the naturally available ingredients. Food industry is one of the most widely popular form of business. There are thousands of cuisines across the world and each one unique in its own way. Even though there are some common ingredients between some cuisines there is always that something unique which makes the ultimate difference in the food.\n",
    "\n",
    "This dataset has the ingredients of the cuisines and the labels of the cuisines. Can we predict the cuisine looking at the ingredients. This is a Natural Languages Processing text classification problem. \n",
    "\n",
    "We start this by loading the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the packages/libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import scorer, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "## Suppressing the warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading , Cleaning and Sneak peak into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the dataset\n",
    "df = pd.read_csv(\"../data/cuisine.csv\")\n",
    "\n",
    "## Text Preprocessing and Cleaning\n",
    "def cleaning(txt):\n",
    "    tokens = [token.lemma_.lower().strip(\" \") for token in nlp(txt) if token.text.isalpha()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleanedingredients'] = df['ingredients'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanedingredients</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>romaine lettuce black olive grape tomato garli...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plain flour ground pepper salt tomato grind bl...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black pepper shallot cornflour cayenne pepper ...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sugar pistachio nut white almond bark flour va...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cleanedingredients      cuisine\n",
       "0  romaine lettuce black olive grape tomato garli...        greek\n",
       "1  plain flour ground pepper salt tomato grind bl...  southern_us\n",
       "2                     water vegetable oil wheat salt       indian\n",
       "3  black pepper shallot cornflour cayenne pepper ...       indian\n",
       "4  sugar pistachio nut white almond bark flour va...      italian"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,[2,1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanedingredients</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32596</th>\n",
       "      <td>low fat sour cream grate parmesan cheese salt ...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32597</th>\n",
       "      <td>shred cheddar cheese crush cheese cracker ched...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32598</th>\n",
       "      <td>kraft zesty italian dress purple onion broccol...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32599</th>\n",
       "      <td>boneless chicken skinless thigh mince garlic s...</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32600</th>\n",
       "      <td>green chile jalapeno chilie onion ground black...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleanedingredients  cuisine\n",
       "32596  low fat sour cream grate parmesan cheese salt ...  italian\n",
       "32597  shred cheddar cheese crush cheese cracker ched...  mexican\n",
       "32598  kraft zesty italian dress purple onion broccol...  italian\n",
       "32599  boneless chicken skinless thigh mince garlic s...  chinese\n",
       "32600  green chile jalapeno chilie onion ground black...  mexican"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,[2,1]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanedingredients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cleanedingredients\n",
       "cuisine                         \n",
       "cajun_creole                1546\n",
       "chinese                     2673\n",
       "french                      2646\n",
       "greek                       1175\n",
       "indian                      3003\n",
       "italian                     7838\n",
       "japanese                    1423\n",
       "mexican                     6438\n",
       "southern_us                 4320\n",
       "thai                        1539"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,[2,1]].groupby('cuisine').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data, training, cross validation and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters::  {'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': ((1, 1), (1, 2)), 'clf__solver': ('saga', 'lbfgs')}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 84.500\n",
      "Best best estimator ::::  Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        strip...penalty='l2', random_state=None, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n",
      "Testing Accuracy:: 85.25\n"
     ]
    }
   ],
   "source": [
    "## Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleanedingredients'], df['cuisine'], test_size=0.30, random_state=42)\n",
    "\n",
    "## Building the model \n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__solver': ('saga', 'lbfgs'),\n",
    "}\n",
    "\n",
    "## Grid Search Cross Validation\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           parameters, \n",
    "                           cv=5,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:: \", parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % round(grid_search.best_score_ * 100,2))\n",
    "print(\"Best best estimator :::: \", grid_search.best_estimator_)\n",
    "\n",
    "print(\"Testing Accuracy::\",round(accuracy_score(grid_search.predict(X_test), y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression algorithm performed the best among host of algorithms tried. This model might not be giving the best possible accuracy but it is performing well. Testing score is better than training score, it is not overfitting.\n",
    "\n",
    "There is scope for improvement to make it more accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
